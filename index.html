<html>
	<head>
		<style type="text/css">
			body{font-family: sans-serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 18px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 14px;font-weight: bold;}
			.text{width: 95%;font-size: 12px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
			.imagecntr{width: 95%;font-size: 12px;text-align: center;vertical-align: middle;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title"><H1>Automatic Speech Sequence Segmentation</H1></div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>Abhishek Anand, Roll No.: 150102003, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Bharath Rao KN, Roll No.: 150102011, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Rahul Kumar, Roll No.: 150102054, Branch: ECE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>

			<div class="imagecntr">
			<img src="https://github.com/anand374/Automatic-Speech-Sequence-Segmentation/blob/master/Pictures/Title.jpg?raw=true" alt="Speaker Identification" width="400px" height=""/>
			</div>

			
			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">

					<!-- Start edit here  -->
					This project aims at segmenting speech sequences based on speaker transitions. Additionally, it will identify the number of speakers along with the zones where single or multiple speakers are active. 
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->


					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						Speaker recognition is to recognize persons from their voice. No two individuals sound identical because their vocal tract shapes, larynx sizes, other parts of their voice production organs, manner of speaking including the use of a particular accent, rhythm, in tonation style, pronunciation pattern and choice of vocabulary are different. State-of-the-art speaker recognition systems use number of these features in parallel, attempting to cover different aspects and employing them in complementary ways to achieve more accurate recognition.
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
						<br>
						A sample <B> (a) Spectrogram </B> and its <B> (b) Radon Transform </B> in one chosen direction.
						<img src="https://github.com/anand374/Automatic-Speech-Sequence-Segmentation/blob/master/Pictures/Spectrogram.JPG?raw=true" alt="Spectrogram and Radon Transform" width="500px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">
                        [1]Pawan K Ajmera, Dattatray V. Jadhav, Raghunath S. Holambe, Text-Independent Speaker Identification using Radon and Discrete Cosine
						Transforms based features from Speech Spectrogram [2011] </br>
						This paper presents a new feature extraction technique for speaker recognition using Radon transform
						(RT) and discrete cosine transform (DCT). The spectrogram is compact, efficient in representation and
						carries information about acoustic features in the form of pattern. In the proposed method, speaker
						specific features have been extracted by applying image processing techniques to the pattern available
						in the spectrogram.
						<!-- Start edit here  -->
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						It has been established that the phonetic information can be recovered by examining the spectrogram in a visual domain  rather than the conventional audio domain. Visual domain working is better because it is easier to verbalize speech spectrogram process than to verbalize hearing process.
						<br>
						We present a computationally efficient text-independent speaker recognition technique. The essence of this technique lies in formulating the speaker recognition problem in to pattern recognition of images and resolving it using machine learning tools. The technique computes the Radon projections of the speech spectrogram in different directions to derive the speaker's voice pattern. Discrete cosine transform (DCT) of Radon projection reduces the 
						feature vector dimension to derive effective and efficient speaker.
						<BR>
						Block Diagram representing the process flow.<br>
						<img src="https://github.com/anand374/Automatic-Speech-Sequence-Segmentation/blob/master/Pictures/Block%20Diagram.JPG?raw=true" alt="Block Diagram" width="" height="500px"/>
						<!-- Stop edit here -->

					</div>
				</div>
				<HR>
				<H3><text align="center" color="red">This section is still under making.</text></H3>
				<HR>
				<div class="subsection">
					<div class="heading">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					Write something here.
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">
					

						<!-- Start edit here  -->
					
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Discussion</div>
					<div class="text">
					Why Spectogram?</br>
						In speaker identification system, high dimension feature set is
						preferred to enhance the performance. However, increased feature dimension requires more computational time and storage
						space. The classifier using high dimension feature set also
						requires more parameters to characterize a speaker model, e.g.
						Gaussian Mixture Model (GMM). This increases computational complexity, making real-time implementation more difficult. Furthermore, a large amount of data is required for the
						training. An alternative approach to this is to extract effective and
						efficient feature vectors.Mel frequency cepstral coefficients (MFCC) and linear
						prediction cepstral coefficients (LPCC) are the two most
						common feature extraction techniques in speaker identification.
						MFCC is generally used because of its robustness in speaker
						identification . Since the elements of feature vectors are
						generally correlated , a large number of mixtures with full
						covariance matrix are necessary to provide good approximation
						. The GMM with diagonal covariance matrix is used for both
						speaker identification and verification because of its computational simplicity
						Contextual variations in speech are better represented using
						a spectrogram and hence it is widely used as a tool for speech
						analysis. A spectrogram is a graphical display of the
						squared magnitude of the time-varying spectral characteristics of
						speech. It is compact and efficient in representation carrying
						information about energy, pitch, fundamental frequency,formants and timing.Spectrogram reading techniques have revealed	that a speech spectrogram contains rich acoustic features that could be valuable in an automatic speech and speaker recognition system. The technique we use here formulates the speaker identification
						problem into pattern recognition of images and resolving it using machine learning tools. The technique uses Radon Projections of speech spectogram in different angles to derieve the speaker's voice pattern. And to get more efficient and effective speaker features we use DCT (Dicrete Cosine Transform). As our dataset was small enough we did not use the DCT in our project. <br> 


						<p>Radon Transform: </br>
						 Radon transform is based on the parameterization of lines and
						the evaluation of integrals of an image along these lines. Due to
						inherent properties of Radon transform, it is a useful tool to
						capture the directional features of an image. Basically, the Radon
						transform adds up the pixel intensity values in the given image
						(spectrogram) or time frequency distribution along a straight line
						in a particular direction at a specific displacement.
						erator.The spectrogram represents acoustic features like energy,
						pitch, fundamental frequency, formants and time in the form of
						a pattern.The Radon transform effectively captures
						these features in the pattern by projecting it onto different
						orientation slices. The Radon projection is obtained by summing
						all the intensity values of those pixels that are within the circle
						surrounding the pattern to be recognized and on the line that is
						perpendicular to the ridge.Another advantage of using Radon transform in the proposed
						approach is its insensitivity to additive noise.</p>
						<!--Insert radonformula-->

						Discrete Cosine Transform: <br>

						DCT is a well-known signal analysis tool used in data compression due to its compact representation capability.The DCT is similar to the discrete Fourier transform: it transforms a signal or image from the spatial domain to the frequency domain. It has an excellent energy compaction property for highly correlated data.
						This helps in reduction of the feature vector dimension. 
						<!-- Insert DCT formula pic -->



						<!-- Start edit here  -->
						
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
